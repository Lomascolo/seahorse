# Copyright (c) 2015, CodiLime Inc.

########
# Hadoop cluster deployment
#
# Run with:
# $ ansible-playbook hadoop.yaml -i hosts --extra-vars "env_prefix=ds-virt-env-"
#
########

---
- name: Builds Hadoop docker image
  hosts: localhost
  vars_files:
    - vars/docker.yml
  roles:
    - hadoop

- name: Exports Hadoop docker image
  hosts: localhost
  vars_files:
    - vars/docker.yml
  tasks:
    - include: tasks/save_docker_image.yml docker_image=ds-hadoop download_dir="{{hadoop_docker_dir}}"

- name: Copies Hadoop docker image
  hosts: hadoop-cluster
  user: ubuntu
  sudo: yes
  vars_files:
    - vars/docker.yml
  tasks:
    - name: Assures docker dir exists
      file: path={{hadoop_docker_dir}} state=directory
    - include: tasks/copy_docker_image.yml docker_tar_image=ds-hadoop-docker.tar docker_dir={{hadoop_docker_dir}} download_dir="{{hadoop_docker_dir}}"

- name: Imports Hadoop docker image
  hosts: hadoop-cluster
  user: ubuntu
  sudo: yes
  vars_files:
    - vars/docker.yml
  tasks:
    - include: tasks/load_docker_image.yml docker_image=ds-hadoop docker_dir={{hadoop_docker_dir}}

- name: Ensure HDFS data directory is present
  hosts: hadoop-cluster
  user: ubuntu
  sudo: yes
  vars_files:
    - vars/docker.yml
  tasks:
    - name: Create HDFS directory
      file: path="{{hadoop_data_dir}}" state=directory owner=ubuntu group=ubuntu mode=755

- name: Runs Hadoop slave image
  hosts: slaves
  user: ubuntu
  sudo: yes
  vars_files:
    - vars/docker.yml
  tasks:
    - name: Register running Docker containers
      register: docker_containers
      command: docker ps -a

    - name: Remove previous container
      command: docker rm -f ds-hadoop
      when: docker_containers.stdout.find('ds-hadoop') != -1

    - name: Run Hadoop container
      command: >
        docker run --restart=always -d
          --net=host
          --volumes-from ds-spark
          -v /etc/hosts:/tmp/hosts.orig:ro
          -v "{{hadoop_data_dir}}:/hdfs"
          -e ENV_PREFIX={{env_prefix}}
          -e IS_MASTER=0
          --name ds-hadoop ds-hadoop

- name: Runs Hadoop master image
  hosts: master
  user: ubuntu
  sudo: yes
  vars_files:
    - vars/docker.yml
    - vars/deployment.yml
  tasks:
    - name: Register running Docker containers
      register: docker_containers
      command: docker ps -a

    - name: Remove previous container
      command: docker rm -f ds-hadoop
      when: docker_containers.stdout.find('ds-hadoop') != -1

    - name: Run Hadoop container
      command: >
        docker run --restart=always -d
          --net=host
          --volumes-from ds-spark
          -v /etc/hosts:/tmp/hosts.orig:ro
          -v {{hadoop_data_dir}}:/hdfs
          -v {{ge_install_dir}}:{{ge_install_dir}}
          -e ENV_PREFIX={{env_prefix}}
          -e IS_MASTER=1
          -e NUMBER_OF_SLAVES={{groups['slaves'] | length}}
          --name ds-hadoop ds-hadoop
