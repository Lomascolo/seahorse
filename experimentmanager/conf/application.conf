server {
  host = "0.0.0.0"
  port = 9080
  startup.timeout = 5000
}

auth-service {
  endpoint = "http://10.10.1.76:35357/v2.0/"
  identity = "service:experimentmanager"
  password = "MmUyN2U2ZDk5ZTlh"
  timeout {
    connection = 1000
    socket = 1000
  }
}

roles {
  experiments {
    get = "experiments:get"
    update = "experiments:update"
    create = "experiments:create"
    list = "experiments:list"
    delete = "experiments:delete"
    launch = "experiments:launch"
    abort = "experiments:abort"
  }
}

experiments.api.prefix = "v1/experiments"
operations.api.prefix = "v1/operations"
models.api.prefix = "v1/models"

runningexperiments.timeout = 3000
entitystorage.label = "default"

runningexperiments.override.with.mock = false
runningexperiments.mock {
  failureprobability = 0.002
  tickdelay = 5000
}

entityStorage {
  actorSystemName = "root-actor-system"
  hostname = "172.28.128.1"
  port = 2552
  actorName = "EntitiesApiActor"
  timeoutSeconds = 5

  client {
    localAddress = "localhost"
    localPort = 0
  }
}

spark {
  executor.memory = "1g"
  driver.memory = "512m"
}

hdfs {
  hostname = "ds-dev-env-master"
  port = 8020
}


cassandra {
  host = "10.10.1.94"
  port = "9042"
  reconnect.delay = 5000
  credentials {
    user = "cassandra"
    password = "cassandra"
  }
  experiments {
    table = "experiments"
    keyspace = "experimentmanager"
  }
}

deepsense {
  akka {
    actor {
      provider = "akka.remote.RemoteActorRefProvider"
    }
    remote {
      enabled-transports = ["akka.remote.netty.tcp"]
      netty.tcp {
        hostname = "172.28.128.1"
        port = 0
      }
    }
  }
}

hadoop {
  yarn.resourcemanager.hostname = "ds-dev-env-master"
  yarn.log.server.url = "http://ds-dev-env-master:19888/jobhistory/logs/"
  fs.default.name = "hdfs://ds-dev-env-master:8020"
}

